import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
from datetime import timedelta
# 데이터 불러오기

df['PDD'] = pd.to_datetime(df['PDD'])
df = df.sort_values('PDD')
# 파생 피처 생성
df['log_parcel'] = np.log1p(df['FCST Parcel'])
df['diff_parcel'] = df['FCST Parcel'].diff()
df['ma7_parcel'] = df['FCST Parcel'].rolling(7).mean()
df['std7_parcel'] = df['FCST Parcel'].rolling(7).std()
df['dayofweek'] = df['PDD'].dt.dayofweek
df['is_parcel_spike'] = (df['FCST Parcel'] - df['ma7_parcel']) / df['ma7_parcel']
df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
df['is_month_start'] = (df['PDD'].dt.day <= 3).astype(int)
feature_cols = ['log_parcel', 'diff_parcel', 'ma7_parcel', 'std7_parcel',
               'dayofweek', 'is_parcel_spike', 'is_weekend', 'is_month_start']
lookback_days = 25
bootstrap_runs = 30
target_dates = pd.date_range('2025-04-08', '2025-05-07')
results = []
residual_data = []
print("=== 4월 8일 ~ 5월 7일 예측 (보정 모델 포함) ===")
# 1. residual 학습 데이터 수집
for target_date in target_dates:
   train_df = df[(df['PDD'] < target_date) & (df['PDD'] >= target_date - pd.Timedelta(days=lookback_days))].dropna()
   test_df = df[df['PDD'] == target_date - pd.Timedelta(days=1)]
   actual_df = df[df['PDD'] == target_date]
   if train_df.empty or test_df.empty or actual_df.empty:
       continue
   X_train = train_df[feature_cols]
   y_train = train_df['N1_OB']
   X_test = test_df[feature_cols]
   y_actual = actual_df['N1_OB'].values[0]
   preds = []
   for _ in range(bootstrap_runs):
       idx = np.random.choice(len(X_train), len(X_train), replace=True)
       model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1)
       model.fit(X_train.iloc[idx], y_train.iloc[idx])
       pred = model.predict(X_test)[0]
       preds.append(pred)
   pred1 = np.mean(preds)
   residual = y_actual - pred1
   residual_data.append({**X_test.iloc[0].to_dict(), 'residual': residual})
# 2. 보정 모델 학습
res_df = pd.DataFrame(residual_data).dropna()
res_model = XGBRegressor(n_estimators=100, max_depth=2, learning_rate=0.1)
res_model.fit(res_df[feature_cols], res_df['residual'])
# 3. 최종 예측 + 평가
for target_date in target_dates:
   train_df = df[(df['PDD'] < target_date) & (df['PDD'] >= target_date - pd.Timedelta(days=lookback_days))].dropna()
   test_df = df[df['PDD'] == target_date - pd.Timedelta(days=1)]
   actual_df = df[df['PDD'] == target_date]
   if train_df.empty or test_df.empty or actual_df.empty:
       continue
   X_train = train_df[feature_cols]
   y_train = train_df['N1_OB']
   X_test = test_df[feature_cols]
   y_actual = actual_df['N1_OB'].values[0]
   # 1차 예측 (부트스트랩 평균)
   preds = []
   for _ in range(bootstrap_runs):
       idx = np.random.choice(len(X_train), len(X_train), replace=True)
       model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1)
       model.fit(X_train.iloc[idx], y_train.iloc[idx])
       pred = model.predict(X_test)[0]
       preds.append(pred)
   pred1 = np.mean(preds)
   std_pred = np.std(preds)
   # 보정 예측
   residual_pred = res_model.predict(X_test)[0]
   final_pred = pred1 + residual_pred
   # 실패확률 계산
   fail_prob = 2 * norm.sf(abs(y_actual - final_pred) / std_pred)
   # 평가
   ape = abs(final_pred - y_actual) / y_actual * 100
   lower = final_pred - 1.96 * std_pred
   upper = final_pred + 1.96 * std_pred
   results.append({
       'date': target_date.date(),
       'pred': final_pred,
       'actual': y_actual,
       'APE': ape,
       'fail_prob': fail_prob,
       'lower': lower,
       'upper': upper
   })
   print(f"[{target_date.date()}] 예측 TO: {final_pred:.2f} (± {1.96 * std_pred:.2f}) | 실제 TO: {y_actual:.2f} | APE: {ape:.2f}% | 실패확률: {fail_prob:.2%}")
# 전체 성능 평가
if results:
   pred_arr = [r['pred'] for r in results]
   actual_arr = [r['actual'] for r in results]
   mae = mean_absolute_error(actual_arr, pred_arr)
   rmse = mean_squared_error(actual_arr, pred_arr, squared=False)
   mape = np.mean([r['APE'] for r in results])
   print("\n=== 전체 성능 평가 (보정 모델 포함) ===")
   print(f"MAE: {mae:.3f}, RMSE: {rmse:.3f}, MAPE: {mape:.2f}%")
