from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import PromptTemplate
from langchain.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader

# 단계 1: 문서 로드(Load Documents)
loader = TextLoader('C:/Users/RomainDHKuRecruiting/Romain/training_set.txt', encoding='UTF8')
docs = loader.load()

# 단계 2: 문서 분할(Split Documents)
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
split_documents = text_splitter.split_documents(docs)

# 단계 3: 임베딩(Embedding) 생성
#from transformers import AutoTokenizer
from langchain.embeddings import HuggingFaceEmbeddings
 
#tokenizer = AutoTokenizer.from_pretrained("jhgan/ko-sroberta-multitask")
embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")

# 단계 4: DB 생성(Create DB) 및 저장
# 벡터스토어를 생성합니다.
vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)

# 단계 5: 검색기(Retriever) 생성
# 문서에 포함되어 있는 정보를 검색하고 생성합니다.
retriever = vectorstore.as_retriever()

# 단계 6: 프롬프트 생성(Create Prompt)
# 프롬프트를 생성합니다.
prompt = PromptTemplate.from_template(
    """You are an korean assistant for question-answering tasks. 
    Use the following pieces of retrieved context to answer the question. 
    If you don't know the answer, just say that you don't know in korean. 
    you Must answer in Korean.
    should answer in 3 sentence.

#Context: 
{context}

#Question:
{question}

#Answer:"""
)

# 단계 7: 언어모델(LLM) 생성
# 모델(LLM) 을 생성합니다.
from langchain_community.chat_models import ChatOllama
#llm = ChatOllama(model="Llama-3-Open-Ko-8B-Q8_0:latest")
llm = ChatOllama(model="EEVE-Korean-10.8B")

# 단계 8: 체인(Chain) 생성
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
